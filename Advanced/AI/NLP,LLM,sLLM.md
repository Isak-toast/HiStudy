# NLP, LLM, sLLM

> 작성자 : [김이삭](https://github.com/Isak-toast)

<details>
<summary>Table of Contents</summary>

- [자연어 처리(NLP)의 기초](#자연어-처리nlp의-기초)
- [대규모 언어 모델(LLM)의 등장](#대규모-언어-모델llm의-등장)
- [소형 언어 모델(sLM)](#소형-언어-모델slm)
- [NLP와 LLM의 실제 적용 사례](#nlp와-llm의-실제-적용-사례)
- [미래 전망과 도전 과제](#미래-전망과-도전-과제)
- [결론](#결론)
- [부록 및 참고 자료](#부록-및-참고-자료)

</details>

---

## 📍서론
인공지능(AI) 기술의 발전은 정보 수집, 분석, 공유 방식을 혁신적으로 변화시켰습니다. 이 혁신의 중심에는 자연어 처리(NLP), 대규모 언어 모델(LLM), 그리고 최근의 혁신인 소형 언어 모델(sLM)이 있습니다. 이 기술들로 인해 컴퓨터는 인간의 언어를 '이해'하고 '파악'하며, 우리와 자연스럽게 소통할 수 있게 되었습니다.

이 글에서는 NLP의 기본적인 원리부터 시작해, LLM이 어떻게 AI 분야에 혁명을 일으켰는지, 자원이 제한된 환경에서도 효과적으로 작동하는 sLM의 중요성까지 탐구합니다. 또한, 이 기술들이 비즈니스, 의료, 교육 등 다양한 분야에서 어떻게 활용되고 있는지 실제 사례를 통해 살펴볼 예정입니다.

하지만, 이러한 기술 발전에도 불구하고 데이터 프라이버시, 알고리즘 편향, 정보 진위성 검증 등 윤리적 및 사회적 도전 과제에 직면해 있습니다. 글의 마지막 부분에서는 이 문제들과 그 해결 방안을 논의하며, 지속 가능한 AI 개발을 위한 제안을 모색합니다.

이 글을 통해 NLP와 LLM, sLM이 어떻게 우리의 일상과 기술 환경에 깊숙이 통합되어 있는지, 그리고 앞으로 이 기술들이 우리의 미래에 어떤 변화를 가져올 수 있는지에 대한 통찰을 제공하고자 합니다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKlwXe%2FbtqQNqhj6a1%2FESDqEdieQwV3wkm5AxU2y0%2Fimg.png)

## 📍자연어 처리(NLP)의 기초
NLP는 컴퓨터가 인간의 언어를 이해하고, 의미를 파악하여 자연스러운 언어로 커뮤니케이션할 수 있게 하는 AI의 한 분야입니다. 이는 컴퓨터에게 문자 메시지를 읽고 이해하게 하거나, 음성 명령에 반응하고, 심지어 인간처럼 자연스러운 대화를 나눌 수 있는 능력을 부여합니다.


### NLP의 정의와 핵심 원리
자연어 처리(NLP)는 컴퓨터가 인간의 언어를 '이해'하고 그 의미를 '파악'하여, 우리가 사용하는 자연스러운 언어로 커뮤니케이션할 수 있게 하는 인공지능(AI) 분야의 한 갈래입니다. 이 기술은 컴퓨터에게 문자 메시지를 읽고 이해하게 하거나, 음성 명령에 반응하고, 심지어는 인간처럼 자연스러운 대화를 나눌 수 있는 능력을 부여합니다.

![](https://heung-bae-lee.github.io/image/What_is_Natural_language_processing.png)


### NLP의 역사적 발전과 현재의 중요성
초기 단계: 규칙 기반 시스템
1950-1980년대: NLP의 초기 연구는 주로 규칙 기반 시스템에 초점을 맞추었습니다. 이는 언어의 구조와 문법 규칙을 명시적으로 프로그래밍하여 컴퓨터가 텍스트를 분석하고 생성할 수 있도록 했습니다. 예를 들어, ELIZA와 같은 초기 대화형 프로그램은 매우 단순한 규칙과 패턴 매칭 기술을 사용하여 인간과의 대화를 시뮬레이션했습니다.

![](https://velog.velcdn.com/images/yeons0110/post/207e0aba-0804-4d61-a453-ed5e00f30bd5/image.png)

통계적 방법의 도입
1980-2000년대: 이 시기에는 통계적 방법과 기계 학습이 NLP에 도입되기 시작했습니다. 대량의 언어 데이터로부터 패턴을 학습하고, 이를 바탕으로 언어 관련 작업을 수행하는 모델이 개발되었습니다. 예를 들어, 통계적 기계 번역은 이 시기의 주요 성과 중 하나였습니다.
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqpO3R%2Fbtrqui9Hcnb%2F2L90GkH0JFhcizXLiKhGi1%2Fimg.png)

NLP의 여정은 1950년대에 시작되어, 규칙 기반 시스템에서부터 오늘날의 AI와 머신러닝 알고리즘에 이르기까지 계속 발전해왔습니다. 초기에는 간단한 패턴 인식과 규칙을 기반으로 한 언어 변환 방법이 주를 이루었습니다. 하지만, 1980년대 통계적 방법의 도입으로 이 분야는 크게 발전하게 되었고, 21세기에 들어서면서 딥러닝 기술의 발전과 함께 NLP는 급격히 진화했습니다. 오늘날 NLP는 거의 모든 디지털 플랫폼과 상호작용에서 중요한 역할을 하고 있습니다.

### 기본적인 NLP 기술과 알고리즘 소개 (예: 토큰화, 형태소 분석, 구문 분석 등)
NLP를 이해하려면 몇 가지 기본 개념과 기술을 알아야 합니다:

토큰화(Tokenization): 텍스트를 더 작은 단위로 분해하는 과정입니다. 이는 문장을 개별 단어나 구에 분리하거나, 문단을 개별 문장으로 나누는 작업을 포함할 수 있습니다. 토큰화는 텍스트 분석의 첫 단계로, 데이터를 처리하기 쉽게 만듭니다.
![](https://postfiles.pstatic.net/MjAyMDAyMDdfODQg/MDAxNTgxMDQ5MDQyNzg5.57Qx2q7WtL1imesjFstmpjWrYgx27kaArpJMn1GMhbog.3MrYxvAaMl-jezhPTFA3tPR-iMGbxgWv2VhIvJbMlvcg.PNG.shino1025/image.png?type=w773)

형태소 분석(Morphological Analysis): 이 과정에서는 단어를 그 구성 요소로 분해하여 단어의 뿌리, 접두사, 접미사와 같은 형태소를 식별합니다. 이는 단어의 기본 형태를 이해하고, 복잡한 형태의 단어를 처리하는 데 도움이 됩니다.
![](https://heung-bae-lee.github.io/image/Morphs_analysis.png)

구문 분석(Parsing): 문장의 구조를 분석하여 문법적 관계와 구조를 파악하는 과정입니다. 구문 분석을 통해 컴퓨터는 주어, 동사, 목적어 등 문장의 구성 요소와 그들 간의 관계를 이해할 수 있습니다.
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXfHMC%2FbtqQLlN4pe9%2Fm9bw0FSiRF4Irrs9w8MSgK%2Fimg.png)

의미 분석(Semantic Analysis): 단어, 구, 문장의 의미를 분석하는 과정입니다. 이 과정은 단순히 텍스트의 표면적인 의미를 넘어서, 문맥에 따른 의미를 파악하는 데 중점을 둡니다. 의미 분석은 머신러닝과 깊은 학습 모델을 사용하여 진행되곤 합니다.
![](https://velog.velcdn.com/images/monator16/post/b887f5d0-afc3-4b90-9a54-3b440ca53849/image.png)

감정 분석(Sentiment Analysis): 텍스트에서 표현된 감정이나 의견을 식별하고 분류하는 과정입니다. 이는 제품 리뷰, 소셜 미디어 게시물 등에서 소비자의 태도와 반응을 분석하는 데 유용합니다.
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcCgOw6%2FbtqQLkuVWN8%2FQZFLGHkc9pBCnczYh1E1qk%2Fimg.png)

이러한 기술들은 NLP의 다양한 응용 분야에서 결합되어 사용되며, 챗봇, 음성 인식 시스템, 기계 번역, 감정 분석 등 우리가 일상에서 접하는 많은 기능을 가능하게 합니다. NLP는 기술적인 발전뿐만 아니라, 이를 통해 우리의 커뮤니케이션 방식과 정보 접근 방식이 어떻게 변화하고 있는지에 대한 깊은 통찰을 제공합니다.

## 📍대규모 언어 모델(LLM)의 등장
인터넷 시대의 도래와 함께 데이터의 폭발적인 증가는 자연어 처리(NLP) 분야에 전례 없는 혁신을 가져왔습니다. 이 혁신의 정점에 서 있는 것이 바로 대규모 언어 모델(LLM)입니다. 이 모델들은 언어의 복잡성을 이해하고, 사람처럼 자연스러운 텍스트를 생성할 수 있는 능력으로 주목받고 있습니다.

### LLM의 개념 및 구조 소개
LLM은 수십억 개의 파라미터를 사용하여 인터넷 상의 대량의 텍스트 데이터에서 학습합니다. 이 모델들은 단어, 구절, 문장 간의 관계를 학습하여, 주어진 문맥에서 가장 적절한 단어나 구절을 예측할 수 있습니다. 가장 널리 알려진 LLM의 구조로는 Transformer가 있습니다. Transformer는 '어텐션 메커니즘'을 사용하여 텍스트 내의 각 단어가 서로 어떻게 관련되어 있는지를 파악하며, 이를 통해 문맥을 더욱 효과적으로 이해할 수 있습니다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFjgoc%2FbtrQJa6e2ky%2FtVPqUPvIEdEumkMGdzOp51%2Fimg.png)

![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*RrBusaO1xMzLKn-Ibn9Jtg.png)

### LLM의 역사적 발전
딥 러닝의 등장
2000년대 후반: 딥 러닝 기술의 발전은 NLP에 혁명을 가져왔습니다. 인공 신경망, 특히 순환 신경망(RNN)과 그 변형인 장단기 기억(LSTM) 네트워크는 텍스트 데이터의 순차적 특성을 효과적으로 처리할 수 있음을 보여주었습니다. 이를 통해, 기계 번역, 텍스트 요약, 감정 분석 등의 분야에서 상당한 진보가 이루어졌습니다.

Transformer와 LLM의 시대
2017년: Transformer 아키텍처의 소개는 NLP 분야에 또 다른 혁명을 일으켰습니다. Transformer는 병렬 처리 능력과 "어텐션 메커니즘"을 통해 문장 내 단어 간의 관계를 더 잘 이해할 수 있게 함으로써, 이전 모델들보다 훨씬 더 복잡하고 긴 텍스트를 효율적으로 처리할 수 있게 되었습니다. 이 아키텍처는 대규모 언어 모델의 개발로 이어졌으며, Google의 BERT와 OpenAI의 GPT 시리즈와 같은 혁신적인 모델이 등장하게 되었습니다.

대규모 언어 모델의 발전
2018년 이후: BERT, GPT-2, GPT-3와 같은 모델들은 대량의 인터넷 텍스트 데이터에서 훈련되어, 문맥에 따른 언어의 복잡성과 뉘앙스를 놀랍도록 잘 모델링하게 되었습니다. 이러한 LLM은 단순히 텍스트를 생성하고 이해하는 것을 넘어, 텍스트 요약, 질문에 답하기, 문서 생성 등과 같은 다양한 고급 언어 작업을 수행할 수 있게 되었습니다.


### LLM 훈련 과정과 기술적 도전 과제
LLM의 훈련은 엄청난 양의 계산 자원을 필요로 합니다. 이 모델들은 종종 수 주 혹은 수 개월에 걸쳐 특수한 하드웨어에서 훈련됩니다. 훈련 과정에서는 큰 규모의 데이터 세트를 사용하여 모델이 수많은 언어 패턴과 구조를 학습하게 됩니다. 하지만 이 과정은 비용이 많이 들고, 에너지 소모가 크며, 데이터의 편향성이 모델에 영향을 미칠 수 있다는 도전 과제를 내포하고 있습니다.

### LLM이 가능하게 한 혁신적인 언어 작업 사례 (예: GPT, BERT)
LLM의 등장은 여러 혁신적인 언어 작업을 가능하게 했습니다. 대표적인 예로 GPT와 BERT가 있습니다.

GPT(Generative Pre-trained Transformer): GPT 시리즈는 텍스트를 생성하는 능력이 탁월합니다. 주어진 입력에 대해 자연스럽고 일관된 내용을 생성할 수 있으며, 이는 스토리텔링, 기사 작성, 심지어는 코드 생성에 이르기까지 다양하게 활용됩니다.

BERT(Bidirectional Encoder Representations from Transformers): BERT는 특히 언어 이해 작업에서 강력한 성능을 발휘합니다. 이 모델은 문장 내 각 단어의 문맥을 양방향으로 파악하여, 문장의 의미를 더 정확하게 이해할 수 있습니다. BERT는 검색 엔진 최적화, 질문에 대한 답변 생성, 텍스트 요약 등에 활용됩니다.

![](https://i.imgur.com/S0equuG.png)

LLM의 이러한 발전은 AI가 인간의 언어를 이해하고 생성하는 방식을 근본적으로 변화시켰습니다. 이 모델들은 놀라운 수준의 자연스러움과 정확성으로 텍스트를 다루며, 이는 고객 서비스, 콘텐츠 생성, 교육 등 다양한 분야에서 혁신을 가능하게 하고 있습니다. LLM의 앞으로의 발전은 우리가 언어와 정보를 다루는 방식을 더욱 풍부하고 다층적으로 만들 것입니다.

## 📍소형 언어 모델(sLM)
### 소형 언어 모델(sLM)의 출현
최근: LLM의 크기와 복잡성이 계속 증가함에 따라, 연구자들은 더 적은 자원으로도 효과적인 성능을 낼 수 있는 소형 언어 모델(sLM) 개발에 관심을 기울이기 시작했습니다. 이 모델들은 LLM의 핵심 기능을 유지하면서도 더 적은 데이터, 더 적은 파라미터, 그리고 더 적은 연산으로 효율적으로 작동할 수 있도록 설계되었습니다. 이러한 접근 방식은 모델의 확장성을 높이고, 더 넓은 범위의 응용 프로그램과 장치에 NLP 기능을 통합할 수 있는 가능성을 열어주었습니다.


### sLM의 중요성
자원 효율성: sLM은 더 적은 연산 자원으로도 우수한 성능을 낼 수 있어, 에너지 소비와 비용을 크게 줄일 수 있습니다.
접근성: 소형 모델은 더 많은 개발자와 조직이 NLP 기술을 사용할 수 있게 함으로써, AI의 민주화를 촉진합니다.
응용 프로그램의 다양성: sLM은 모바일 장치, IoT 기기 등 제한된 연산 능력을 가진 환경에서도 동작할 수 있어, NLP의 적용 범위를 확장합니다.

![](https://media.disquiet.io/images/makerlog/499bae9e579e054beacbc959fec95fb6f5b35a24f0a7c06e0100c220606cbc19)

### sLM의 정의와 필요성
소형 언어 모델(sLM)은 대규모 언어 모델(LLM)의 효율적인 대안으로, 더 적은 데이터, 더 적은 파라미터, 그리고 더 적은 연산 자원을 사용하여 핵심 NLP 작업을 수행할 수 있도록 설계되었습니다. 이러한 모델들은 모바일 장치, IoT 기기와 같이 연산 능력이 제한된 환경에서도 NLP 기능을 구현할 수 있게 합니다. sLM의 필요성은 AI 기술의 접근성 향상, 에너지 소비 및 비용 절감, 그리고 AI 기술의 더 넓은 적용 범위를 포함합니다.

### 도메인 특화 모델의 개발과 적용 사례
도메인 특화 소형 언어 모델은 특정 분야 또는 응용 프로그램에 맞춰 최적화되어, 관련 데이터와 용어에 대한 높은 이해도를 가집니다. 이러한 모델들은 의료, 법률, 금융 등 특정 분야의 전문 용어와 컨텍스트를 더 잘 이해하고 처리할 수 있습니다. 예를 들어, 의료 분야에서는 질병 진단, 치료 방안 제시, 환자 기록 분석 등에 sLM을 사용할 수 있습니다.


### sLM의 장점과 한계
sLM의 주요 장점은 효율성과 접근성입니다. 이 모델들은 비교적 적은 자원으로도 우수한 NLP 성능을 제공하며, 다양한 장치와 환경에서 NLP 기능을 가능하게 합니다. 하지만, sLM은 LLM에 비해 학습할 수 있는 데이터의 양과 복잡성이 제한되어 있으므로, 일부 고급 언어 이해 및 생성 작업에서는 LLM보다 성능이 떨어질 수 있습니다.


## 📍NLP와 LLM의 실제 적용 사례
### 비즈니스, 의료, 교육 등 다양한 분야에서의 활용 사례
NLP와 LLM 기술은 비즈니스 분석, 고객 서비스 자동화, 의료 진단 지원, 교육 자료 개인화 등 다양한 분야에서 활용됩니다. 예를 들어, 비즈니스 분석에서는 시장 동향, 소비자 선호도, 경쟁사 분석 등을 위해 NLP를 활용할 수 있으며, 의료 분야에서는 환자 기록 분석, 질병 정보 검색, 진단 지원 시스템 등에 LLM을 사용할 수 있습니다.
![](https://www.igloo.co.kr/wp-content/uploads/2023/08/%EA%B7%B8%EB%A6%BC1.png)

### 혁신적인 NLP 및 LLM 기반 서비스와 제품 소개
1. 번역 서비스:

[구글 번역](https://translate.google.com/): 108개 이상의 언어를 지원하는 실시간 번역 서비스입니다. 텍스트, 음성, 이미지 번역이 가능하며, 딥 러닝 기술을 사용하여 정확하고 자연스러운 번역 결과를 제공합니다.
[파파고](https://papago.naver.com/?sk%3Dauto%26st%3D%EC%96%B4%EB%A6%B0%EC%95%A0%EB%8F%84%20%EA%B7%B8%EC%AF%A4%EC%9D%80%20%ED%95%A0%20%EC%88%98%20%EC%9E%88%EC%9D%84%20%EA%B1%B0%EC%95%BC.%26tk%3Den): 네이버에서 제공하는 번역 서비스입니다. 13개 언어를 지원하며, AI 기반 번역 엔진을 사용하여 정확하고 자연스러운 번역 결과를 제공합니다.

![](https://blog.kakaocdn.net/dn/DHjZo/btqQLkn7UC2/jPAGP3PllSF8rcmPuL0J5K/img.gif)

2. 챗봇:

카카오톡 챗봇: 카카오톡 플랫폼에서 사용할 수 있는 챗봇입니다. 다양한 정보 제공, 예약, 결제 등의 기능을 제공하며, 사용자 맞춤형 경험을 제공합니다.
네이버 클로바: 네이버에서 제공하는 AI 플랫폼입니다. 챗봇 개발 도구를 제공하여 다양한 분야의 챗봇을 개발하고 운영할 수 있습니다.


그 외
```
Watson Assistant : 자기 학습으로 발전하는 챗봇
Bold360 : 특허받은 "검증된" 챗봇
Rulai : 딥러닝으로 더 깊은 고객 이해를.
LivePerson : 데이터 기반 챗봇의 끝판왕
Inbenta : 규모 있는 기업을 위한 챗봇
Ada : Medium, Shopify, MailChimp가 선택한 챗봇
Vergic : 하이브리드 챗봇
```

3. 콘텐츠 생성:

야놀자 챗봇: 야놀자에서 제공하는 여행 정보 챗봇입니다. 사용자의 여행 계획에 맞춰 숙소, 항공권, 관광지 정보 등을 추천합니다.
스타벅스 챗봇: 스타벅스에서 제공하는 챗봇입니다. 메뉴 주문, 결제, 매장 정보 확인 등의 기능을 제공합니다.

4. 검색:

[구글 검색](https://www.google.com/?&hl=es): 딥 러닝 기술을 사용하여 사용자의 검색 의도를 파악하고 가장 적합한 결과를 제공합니다.
[네이버 검색](https://m.naver.com/): 다양한 검색 필터와 기능을 제공하여 사용자가 원하는 정보를 쉽게 찾을 수 있도록 합니다.

5. 음성 인식:

[구글 어시스턴트](https://play.google.com/store/apps/details?id=com.google.android.apps.googleassistant&hl=ko): 스마트폰, 스마트 스피커 등 다양한 기기에서 사용할 수 있는 음성 비서입니다. 음성 명령을 통해 알람 설정, 음악 재생, 전화 걸기 등의 기능을 사용할 수 있습니다.
[시리](https://www.apple.com/siri/): 애플에서 제공하는 음성 비서입니다. 아이폰, 아이패드 등 다양한 기기에서 사용할 수 있으며, 음성 명령을 통해 다양한 기능을 사용할 수 있습니다.
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FIWVqy%2FbtqQZwN0W1M%2FaKZQKkkyRCamZ02B7fSe01%2Fimg.png)

## 📍미래 전망과 도전 과제
### NLP와 LLM 기술의 발전 방향
NLP와 LLM 기술은 앞으로도 계속 발전할 것입니다. 기술의 진화는 더 정교한 언어 이해 및 생성 능력, 다양한 언어와 방언에 대한 지원 확대, 그리고 AI 기술의 새로운 응용 분야 개발로 이어질 것입니다.


### 윤리적, 사회적 도전 과제 및 해결 방안 논의
NLP와 LLM의 발전은 데이터 프라이버시, 알고리즘 편향, 정보의 진위성 검증 등 윤리적 및 사회적 도전 과제를 제기합니다. 이러한 문제들을 해결하기 위해서는 투명성, 책임감 있는 AI 사용, 다양한 관점과 경험을 반영하는 데이터 세트의 구축 등이 필요합니다.

### 지속 가능한 AI 개발을 위한 제언
AI 기술의 지속 가능한 발전을 위해서는 에너지 효율적인 알고리즘 개발, AI 교육 및 인식 제고, AI 기술의 사회적 가치와 영향 평가 등이 중요합니다. 이를 통해 AI 기술이 사회의 다양한 분야에서 긍정적인 변화를 가져오는 동시에, 잠재적인 부작용을 최소화할 수 있습니다.


## 📍결론
이 발표에서는 NLP와 LLM, 그리고 sLM의 기초적인 이해부터 실제 적용 사례, 미래 전망과 도전 과제에 이르기까지 다양한 주제를 다루었습니다. 이러한 기술들은 이미 우리 생활에 깊숙이 통합되어 있으며, 앞으로도 그 영향력은 계속 확대될 것입니다. NLP와 LLM은 정보 접근성을 향상시키고, 의사소통을 개선하며, 새로운 혁신을 가능하게 하는 등 인간의 언어와 정보를 다루는 방식을 근본적으로 변화시키고 있습니다.

## 📍부록 및 참고 자료

- [NLP - 위키피디아](https://en.wikipedia.org/wiki/Natural_language_processing)
- [Transformer - 위키피디아](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
- [Transformer의 Self-Attention](https://codingopera.tistory.com/43)
- [Attention Is All You Need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [BERT - 위키피디아](https://en.wikipedia.org/wiki/BERT_(language_model))
- [GPT-3 - OpenAI](https://openai.com/blog/gpt-3/)
- [sLM과 sLLM의 차이](https://brunch.co.kr/@iotstlabs/338#:~:text=sLM%EC%9D%80%20%EA%B0%84%EB%8B%A8%ED%95%9C%20%EC%9E%91%EC%97%85%EC%9D%B4%EB%82%98,%EB%B3%B4%EB%8B%88%20sLM%EC%9D%B4%EB%9D%BC%EA%B3%A0%20%EB%8B%B5%ED%95%98%EB%8A%94%EA%B5%B0%EC%9A%94.)